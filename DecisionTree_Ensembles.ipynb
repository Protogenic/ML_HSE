{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HSE 2024: Mathematical Methods for Data Analysis\n",
    "\n",
    "## Homework 4\n",
    "\n",
    "**Warning 1**: You have 10 days for this assignemnt.  **it is better to start early (!)**\n",
    "\n",
    "**Warning 2**: it is critical to describe and explain what you are doing and why, use markdown cells\n",
    "\n",
    "\n",
    "### Contents\n",
    "\n",
    "#### Decision Trees - 7 points\n",
    "* [Task 1](#task1) (0.5 points)\n",
    "* [Task 2](#task2) (0.5 points)\n",
    "* [Task 3](#task3) (2 points)\n",
    "* [Task 4](#task4) (0.5 points)\n",
    "* [Task 5](#task5) (0.5 points)\n",
    "* [Task 6](#task6) (2 points)\n",
    "* [Task 7](#task7) (0.5 points)\n",
    "* [Task 8](#task8) (0.5 points)\n",
    "\n",
    "#### Ensembles - 3 points\n",
    "* [Task 1](#task2_1) (1 point)\n",
    "* [Task 2](#task2_2) (0.7 points)\n",
    "* [Task 3](#task2_3) (0.5 points)\n",
    "* [Task 4](#task2_4) (0.7 points)\n",
    "* [Task 5](#task2_5) (0.1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.727636Z",
     "start_time": "2023-11-09T17:46:40.045013Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (11, 5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task you will be implementing decision tree for the regression by hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 <a id=\"task1\"></a> (0.5 points)\n",
    "\n",
    "Here you should implement the function `H()` which calculates impurity criterion. We will be training regression tree, and will take mean absolute deviation as impurity criterion.\n",
    "\n",
    "* You cannot use loops\n",
    "* If `y` is empty, the function should return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, absolute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.732847Z",
     "start_time": "2023-11-09T17:46:40.729241Z"
    }
   },
   "outputs": [],
   "source": [
    "def H(y):\n",
    "    \"\"\"\n",
    "    Calculate impurity criterion\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.array\n",
    "        array of objects target values in the node\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    H(R) : float\n",
    "        Impurity in the node (measuread by variance)\n",
    "    \"\"\"\n",
    "    if y.size == 0:\n",
    "        return 0\n",
    "    \n",
    "    return mean(absolute(y - mean(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.875430Z",
     "start_time": "2023-11-09T17:46:40.737694Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test the function\n",
    "assert np.allclose(H(np.array([4, 2, 2, 2])), 0.75)\n",
    "assert np.allclose(H(np.array([])), 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 <a id=\"task2\"></a>  (0.5 points)\n",
    "\n",
    "To find the best split in the node we need to calculate the cost function. Denote: \n",
    "- `R` all the object in the node\n",
    "- `j` index of the feature selected for the split\n",
    "- `t` threshold\n",
    "- `R_l` and `R_r` objects in the left and right child nodes correspondingly\n",
    "\n",
    "We get the following cost function:\n",
    "\n",
    "$$\n",
    "Q(R, j, t) =\\frac{|R_\\ell|}{|R|}H(R_\\ell) + \\frac{|R_r|}{|R|}H(R_r) \\to \\min_{j, t},\n",
    "$$\n",
    "\n",
    "Implement the function `Q`, which should calculate value of the cost function for a given feature and threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем столбец под индексом j их массива X, по порогу делим значения y на две части, после чего применяем данную формулу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.877419Z",
     "start_time": "2023-11-09T17:46:40.877407Z"
    }
   },
   "outputs": [],
   "source": [
    "def Q(X, y, j, t):\n",
    "    \"\"\"\n",
    "    Calculate cost function\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        array of objects in the node \n",
    "    y : ndarray\n",
    "        array of target values in the node \n",
    "    j : int\n",
    "        feature index (column in X)\n",
    "    t : float\n",
    "        threshold\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Q : float\n",
    "        Value of the cost function\n",
    "    \"\"\"   \n",
    "    x = X[:, j]\n",
    "    \n",
    "    y_right = y[x > t]\n",
    "    y_left = y[x <= t]\n",
    "\n",
    "    Q = (y_left.size/y.size)*H(y_left) + (y_right.size/y.size)*H(y_right)\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 <a id=\"task3\"></a>  (2 points)\n",
    "\n",
    "Now, let's implement `MyDecisionTreeRegressor` class. More specifically, you need to implement the following methods:\n",
    "\n",
    "- `best_split`\n",
    "- `grow_tree`\n",
    "- `get_prediction`\n",
    "\n",
    "Also, please add `min_samples_leaf` parameter to your class\n",
    "\n",
    "Read docstrings for more details. Do not forget to use function `Q` implemented above, when finding the `best_split`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В методе best_split в цикле берем каждую фичу и каждое значение фичи, принимая ее за пороговое значение, передаем в функцию Q. Если cost меньше лучшего, записываем все значения и формируем сплит. Если с начального значения лучшее значение cost не изменилось, то возвращаем все значения None, сплит больше не улучшает cost.\n",
    "\n",
    "В grow_tree сперва проверяем не терминальная ли нода, если нет, вызываем метод best_split. Если вернуло None, делаем ноду терминальной, задаем prediction и выходим. После задаем все параметры для ноды, высчитываем prediction и рекурсивно вызываем метод для дочерних узлов.\n",
    "\n",
    "Метод get_prediction, наверное, описывать не нужно, сделано буквально то, что написано в docstring'е."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.878647Z",
     "start_time": "2023-11-09T17:46:40.878635Z"
    }
   },
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Class for a decision tree node.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    right : Node() or None\n",
    "        Right child\n",
    "    left : Node() or None\n",
    "        Left child\n",
    "    threshold: float\n",
    "        \n",
    "    column: int\n",
    "        \n",
    "    depth: int\n",
    "        \n",
    "    prediction: float\n",
    "        prediction of the target value in the node \n",
    "        (average values calculated on a train dataset)\n",
    "    is_terminal:bool\n",
    "        indicates whether it is a terminal node (leaf) or not\n",
    "    \"\"\"    \n",
    "    def __init__(self):        \n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        self.threshold = None\n",
    "        self.column = None\n",
    "        self.depth = None\n",
    "        self.is_terminal = False\n",
    "        self.prediction = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        if self.is_terminal:\n",
    "            node_desc = 'Pred: {:.2f}'.format(self.prediction)\n",
    "        else:\n",
    "            node_desc = 'Col {}, t {:.2f}, Pred: {:.2f}'. \\\n",
    "            format(self.column, self.threshold, self.prediction)\n",
    "        return node_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.879812Z",
     "start_time": "2023-11-09T17:46:40.879801Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "class MyDecisionTreeRegressor(RegressorMixin, BaseEstimator):\n",
    "    \"\"\"\n",
    "    Class for a Decision Tree Regressor.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_depth : int\n",
    "        Max depth of a decision tree.\n",
    "    min_samples_split : int\n",
    "        Minimal number of samples (objects) in a node to make a split.\n",
    "    min_samples_leaf: int \n",
    "        Minimum number of samples (objects) in left and right branches after splitting the current node\n",
    "    \"\"\" \n",
    "    def __init__(self, max_depth=3, min_samples_split=2, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "            \n",
    "    def best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        Find the best split in terms of Q of data in a given decision tree node. \n",
    "        Try all features and thresholds. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_objects, n_features)\n",
    "            Objects in the parent node\n",
    "        y : ndarray, shape (n_objects, )\n",
    "            1D array with the object labels. \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        best_split_column : int\n",
    "            Index of the best split column\n",
    "        best_threshold : float\n",
    "            The best split condition.\n",
    "        X_left : ndarray, shape (n_objects_l, n_features)\n",
    "            Objects in the left child\n",
    "        y_left : ndarray, shape (n_objects_l, )\n",
    "            Objects labels in the left child. \n",
    "        X_right : ndarray, shape (n_objects_r, n_features)\n",
    "            Objects in the right child\n",
    "        y_right : ndarray, shape (n_objects_r, )\n",
    "            Objects labels in the right child. \n",
    "        \"\"\"\n",
    "        \n",
    "        # To store best split parameters\n",
    "        best_split_column = None\n",
    "        best_threshold = None\n",
    "        # without splitting\n",
    "        best_cost = H(y)\n",
    "        \n",
    "        for column in range(X.shape[1]):\n",
    "            x = X[:, column]\n",
    "\n",
    "            for i_x in range(0, len(x)):\n",
    "                threshold = x[i_x]\n",
    "\n",
    "                cost = Q(X, y, column, threshold)\n",
    "                if cost < best_cost:\n",
    "                    best_split_column = column\n",
    "                    best_threshold = threshold\n",
    "                    best_cost = cost\n",
    "\n",
    "                    X_left = X[x <= best_threshold]\n",
    "                    y_left = y[x <= best_threshold]\n",
    "                    X_right = X[x > best_threshold]\n",
    "                    y_right = y[x > best_threshold]  \n",
    "\n",
    "        if best_cost == H(y):\n",
    "            return None, None, None, None, None, None\n",
    "    \n",
    "        \n",
    "        return best_split_column, best_threshold, X_left, y_left, X_right, y_right\n",
    "    \n",
    "    def is_terminal(self, node, y):\n",
    "        \"\"\"\n",
    "        Check terminality conditions based on `max_depth`, \n",
    "        `min_samples_split` parameters for a given node. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node, \n",
    "            \n",
    "        y : ndarray, shape (n_objects, )\n",
    "            Object labels. \n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        Is_termial : bool\n",
    "            If True, node is terminal\n",
    "        \"\"\"\n",
    "        if node.depth >= self.max_depth:    \n",
    "            return True\n",
    "        if len(y) < self.min_samples_split:   \n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    def grow_tree(self, node, X, y):\n",
    "        \"\"\"\n",
    "        Reccurently grow the tree from the `node` using a `X` and `y` as a dataset:\n",
    "         - check terminality conditions\n",
    "         - find best split if node is not terminal\n",
    "         - add child nodes to the node\n",
    "         - call the function recursively for the added child nodes\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node() object\n",
    "            Current node of the decision tree.\n",
    "        X : ndarray, shape (n_objects, n_features)\n",
    "            Objects \n",
    "        y : ndarray, shape (n_objects)\n",
    "            Labels\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.is_terminal(node, y) or len(y) <= self.min_samples_leaf:\n",
    "            node.is_terminal = True\n",
    "            node.prediction = np.mean(y)\n",
    "            return\n",
    "\n",
    "        split_column, threshold, X_left, y_left, X_right, y_right = self.best_split(X, y)\n",
    "\n",
    "        if split_column is None or len(X_left) < self.min_samples_leaf or len(X_right) < self.min_samples_leaf:\n",
    "            node.is_terminal = True\n",
    "            node.prediction = np.mean(y)\n",
    "            return\n",
    "\n",
    "\n",
    "        node.column = split_column\n",
    "        node.threshold = threshold\n",
    "        node.is_terminal = False\n",
    "\n",
    "        node.left = Node()\n",
    "        node.left.depth = node.depth + 1\n",
    "        node.left.prediction = np.mean(y_left)\n",
    "\n",
    "        node.right = Node()\n",
    "        node.right.depth = node.depth + 1\n",
    "        node.right.prediction = np.mean(y_right)\n",
    "\n",
    "        self.grow_tree(node.left, X_left, y_left)\n",
    "        self.grow_tree(node.right, X_right, y_right)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the Decision Tree Regressor.\n",
    "            \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        y : ndarray, shape (n_samples,) or (n_samples, n_outputs)\n",
    "            The target values.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        X, y = check_X_y(X, y, accept_sparse=False)\n",
    "        self.is_fitted_ = True\n",
    "\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        \n",
    "        # Initialize the tree (root node)\n",
    "        self.tree_ = Node()                             \n",
    "        self.tree_.depth = 1                            \n",
    "        self.tree_.prediction = np.mean(y)\n",
    "        \n",
    "        # Grow the tree\n",
    "        self.grow_tree(self.tree_, X, y)\n",
    "        return self        \n",
    "    \n",
    "    def get_prediction(self, node, x):\n",
    "        \"\"\"\n",
    "        Get prediction for an object `x`\n",
    "            - Return prediction of the `node` if it is terminal\n",
    "            - Otherwise, recursively call the function to get \n",
    "            predictions of the proper child\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node() object\n",
    "            Current node of the decision tree.\n",
    "        x : ndarray, shape (n_features,)\n",
    "            Array of feature values of one object.\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : float\n",
    "            Prediction for an object x\n",
    "        \"\"\"\n",
    "        \n",
    "        if node.is_terminal == True:\n",
    "            return node.prediction\n",
    "\n",
    "        if x[node.column] > node.threshold:\n",
    "            return self.get_prediction(node.right, x)\n",
    "        else:\n",
    "            return self.get_prediction(node.left, x)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" \n",
    "        Get prediction for each object in X\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The input samples.\n",
    "        Returns\n",
    "        -------\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            Returns predictions.\n",
    "        \"\"\"\n",
    "        # Check input and that `fit` had been called\n",
    "        X = check_array(X, accept_sparse=False)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        \n",
    "        # Get predictions\n",
    "        y_predicted = []\n",
    "        for x in X:\n",
    "            y_curr = self.get_prediction(self.tree_, x)\n",
    "            y_predicted.append(y_curr)\n",
    "        return np.array(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.880754Z",
     "start_time": "2023-11-09T17:46:40.880743Z"
    }
   },
   "outputs": [],
   "source": [
    "# check yourself\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "check_estimator(MyDecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 <a id=\"task4\"></a>  (0.5 points)\n",
    "\n",
    "Load boston dataset and split it on the train ($75\\%$) and test ($25\\%$). Fit Decision Tree of **depth 1 and 2** (root node has **depth 0**) and make the following plot for every case :\n",
    "\n",
    "- Scatter plot of the traning points for each splitted feature (selected for split feature on the x-axis, target variable on the y-axis). Show the resulting thresholds\n",
    "\n",
    "After that, fit analogical model from sklearn and visual it\n",
    "\n",
    "Compare `MAE` on train and test. Have trees overfitted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дерево не переобучилось, значение MAE на тестовой выборке схоже со значением на тренировочной, на некоторых значениях random_state модель показывает себя лучше на тестовой. Обусловить это можно тем, что мы выставили небольшое значение max_depth и модель не успевает подстроится под тренировочные данные слишком сильно.\n",
    "\n",
    "Вот что будет, если выставить max_depth=10:\n",
    "- *Depth 10 - Train: 0.59, Test: 3.43*\n",
    "- *SK Depth 10 - Train: 0.57, Test: 2.36*\n",
    "\n",
    "Scatter plot сделать не смог."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T21:40:52.929277Z",
     "start_time": "2024-11-13T21:40:52.246374Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "df = pd.read_csv('boston_house_prices.csv')\n",
    "\n",
    "X = df.drop('TARGET', axis=1)\n",
    "y = df['TARGET']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 1 - Train: 6.89, Test: 6.22\n"
     ]
    }
   ],
   "source": [
    "model_depth_1 = MyDecisionTreeRegressor(max_depth=1)\n",
    "model_depth_1.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_1 = model_depth_1.predict(X_train)\n",
    "y_test_pred_1 = model_depth_1.predict(X_test)\n",
    "\n",
    "print(f'Depth 1 - Train: {mean_absolute_error(y_train, y_train_pred_1):.2f}, Test: {mean_absolute_error(y_test, y_test_pred_1):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 2 - Train: 5.05, Test: 4.84\n"
     ]
    }
   ],
   "source": [
    "model_depth_2 = MyDecisionTreeRegressor(max_depth=2)\n",
    "model_depth_2.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_2 = model_depth_2.predict(X_train)\n",
    "y_test_pred_2 =model_depth_2.predict(X_test)\n",
    "\n",
    "print(f'Depth 2 - Train: {mean_absolute_error(y_train, y_train_pred_2):.2f}, Test: {mean_absolute_error(y_test, y_test_pred_2):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK Depth 1 - Train: 5.09, Test: 4.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_sk_1 = DecisionTreeRegressor(max_depth=1)\n",
    "model_sk_1.fit(X_train, y_train)\n",
    "\n",
    "y_train_sk_1 = model_sk_1.predict(X_train)\n",
    "y_test_sk_1 =model_sk_1.predict(X_test)\n",
    "\n",
    "print(f'SK Depth 1 - Train: {mean_absolute_error(y_train, y_train_sk_1):.2f}, Test: {mean_absolute_error(y_test, y_test_sk_1):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK Depth 2 - Train: 3.54, Test: 3.66\n"
     ]
    }
   ],
   "source": [
    "model_sk_2 = DecisionTreeRegressor(max_depth=2)\n",
    "model_sk_2.fit(X_train, y_train)\n",
    "\n",
    "y_train_sk_2 = model_sk_2.predict(X_train)\n",
    "y_test_sk_2 =model_sk_2.predict(X_test)\n",
    "\n",
    "print(f'SK Depth 2 - Train: {mean_absolute_error(y_train, y_train_sk_2):.2f}, Test: {mean_absolute_error(y_test, y_test_sk_2):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 <a id=\"task5\"></a>  (0.5 points)\n",
    "\n",
    "Keep working with boston dataset. \n",
    "- Use `GridSearchCV` to find the best hyperparameters among [`max_depth`, `min_samples_leaf`] on 5-Fold cross-validation\n",
    "- Train the model with the best set of hyperparameters on the whole train dataset. \n",
    "- Report `MAE` on test dataset and hyperparameters of the best estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.884202Z",
     "start_time": "2023-11-09T17:46:40.884125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MyDecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 3, 5, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5, 10, 20]},\n",
       "             scoring=&#x27;r2&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(cv=5, estimator=MyDecisionTreeRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 3, 5, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 3, 5, 10, 20]},\n",
       "             scoring=&#x27;r2&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: MyDecisionTreeRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>MyDecisionTreeRegressor(max_depth=10, min_samples_leaf=10)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">MyDecisionTreeRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>MyDecisionTreeRegressor(max_depth=10, min_samples_leaf=10)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MyDecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': [1, 3, 5, 10, 20],\n",
       "                         'min_samples_leaf': [1, 3, 5, 10, 20]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'max_depth': [1, 3, 5, 10, 20], 'min_samples_leaf': [1, 3, 5, 10, 20]}\n",
    "\n",
    "tree = MyDecisionTreeRegressor()\n",
    "grid_search = GridSearchCV(tree, param_grid, cv=5, scoring='r2')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_depth': 10, 'min_samples_leaf': 10}\n",
      "Test MAE: 4.87\n"
     ]
    }
   ],
   "source": [
    "print(f'Params: {grid_search.best_params_}')\n",
    "\n",
    "y_test_pred_gs = model_sk_1.predict(X_test)\n",
    "print(f'Test MAE: {mean_absolute_error(y_test, y_test_pred_gs):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 <a id=\"task6\"></a>  (2 points)\n",
    "\n",
    "Recall definition of bias and variance:\n",
    "$$\n",
    "\\text{Bias}^2 = \\mathbb{E}_{p(x, y)} \\left[  (f(x) - \\mathbb{E}_{\\mathbb{X}}a_{\\mathbb{X}}(x))^2 \\right] \\\\\n",
    "\\text{Variance} = \\mathbb{E}_{p(x, y)} \\left[  \\mathbb{V}_{\\mathbb{X}}( a_{\\mathbb{X}}(x))  \\right]\n",
    "$$\n",
    "\n",
    "We wil now use the following algorithm to estimate bias and variance:\n",
    "\n",
    "1. Use bootsrap to create `n_iter` samples from the original dataset: $X_1, \\dots, X_{n_iter}$\n",
    "2. For each bootstrapped sample define out-of-bag (OOB) sample $Z_1, \\dots, Z_{n_iter}$, which contain all the observations, which did not appear in the corresponding boostraped sample\n",
    "3. Fit the model on $X_i$s and compute predictions on $Z_i$s\n",
    "4. For a given *object* $n$:\n",
    "     - bias^2: squared difference between true value $y_n$ and average prediction (average over the algorithms, for which $n$ was in OOB)\n",
    "     - variance: variance of the prediction (predictions of the algorithms, for which $n$ was in OOB)\n",
    "5. Average bias^2 and variance over all the points\n",
    "    \n",
    "**Implement `get_bias_variance` function, using the algorithm above**\n",
    "\n",
    "*Note:*  You can only use 1 loop (for bootsrap iterations). All other operations should be vectorized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.887222Z",
     "start_time": "2023-11-09T17:46:40.887195Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bias_variance(estimator, x, y, n_iter):\n",
    "    \"\"\" \n",
    "    Calculate bias and variance of the `estimator`. \n",
    "    Using a given dataset and bootstrap with `n_iter` samples. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray, shape (n_samples, n_features)\n",
    "        The input samples.\n",
    "    y : ndarray, shape (n_samples, n_features)\n",
    "        The input samples.\n",
    "    n_iter: int\n",
    "        Number of samples in \n",
    "    Returns\n",
    "    -------\n",
    "    bias2 : float, \n",
    "        Estiamted squared bias\n",
    "    variance : float, \n",
    "        Estiamted variance\n",
    "    \"\"\"\n",
    "    \n",
    "    y = np.array(y)\n",
    "    pred = np.zeros((n_iter, len(y)))\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        bootstrap_indices = np.random.choice(len(x), size=len(x), replace=True)\n",
    "        \n",
    "        bootstrap_x = x[bootstrap_indices]\n",
    "        bootstrap_y = y[bootstrap_indices]\n",
    "        \n",
    "        estimator.fit(bootstrap_x, bootstrap_y)\n",
    "        pred[i, :] = estimator.predict(x)\n",
    "    \n",
    "    mean_pred = np.mean(pred, axis=0)\n",
    "\n",
    "    bias2 = np.mean((mean_pred - y) ** 2)\n",
    "    variance = np.mean(np.var(pred, axis=0))\n",
    "    \n",
    "    return bias2, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.888721Z",
     "start_time": "2023-11-09T17:46:40.888706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.4878145711937965, 8.327945471506972)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "estimator = MyDecisionTreeRegressor(max_depth=8, min_samples_split=15)\n",
    "\n",
    "get_bias_variance(estimator, X_train.values, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 <a id=\"task7\"></a>  (0.5 points)\n",
    "\n",
    "Compute bias and variance for the trees with different min_samples_split. Plot how bias and variance change as min_samples_split increases. \n",
    "\n",
    "Comment on what you observe, how does your result correspond to theory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.889695Z",
     "start_time": "2023-11-09T17:46:40.889683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1100x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_values = [2, 5, 10, 15, 20, 30, 50, 100, 200]\n",
    "\n",
    "bias = []\n",
    "variance = []\n",
    "\n",
    "for split in split_values:\n",
    "    estimator = DecisionTreeRegressor(min_samples_split=split, random_state=100)\n",
    "    b, v = get_bias_variance(estimator , X_train.values, y_train, 10)\n",
    "    bias.append(b)\n",
    "    variance.append(v)\n",
    "\n",
    "plt.plot(split_values, bias, label=\"Bias\", marker='o')\n",
    "plt.plot(split_values, variance, label=\"Variance\", marker='o')\n",
    "plt.xlabel(\"min_samples_split value\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С увеличением значения min_samples_split bias увеличивается, что закономерно, ведь модель все более и более обобщенно подстраивается под модель, \"не вдаваясь в детали\". Почти на всех random_state variance мало изменяется при изменении min_samples_split, что отклоняется от теории, ведь чем больше min_samples_split, тем меньше модель подстраивается под конкретную выборку, значит разброс предсказаний модели должен быть меньше, но в этом случае этого мы не неблюдаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 <a id=\"task8\"></a>  (0.5 points)\n",
    "\n",
    "Let's try to reduce variance with bagging. Use `sklearn.ensemble.BaggingRegressor` to get an ensemble and compute its bias and variance. \n",
    "\n",
    "Answer the following questions:\n",
    " - How bagging should affect bias and variance in theory?\n",
    " - How bias and variance change (if they change) compared to an individual tree in you experiments? \n",
    " - Do your results align with the theory? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-09T17:46:40.891228Z",
     "start_time": "2023-11-09T17:46:40.891211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias: 6.601905903992995\n",
      "Variance: 3.7578331899351216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "estimator = MyDecisionTreeRegressor(max_depth=10, min_samples_split=10)\n",
    "model_bagging = BaggingRegressor(estimator, 20)\n",
    "\n",
    "b, v = get_bias_variance(model_bagging, X_train.values, y_train, 10)\n",
    "print(f'Bias: {b}\\nVariance: {v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Бэггинг в первую очередь используется для снижения variance, он не дает модели переобучится, так как учитывает предсказания нескольких моделей, обученных на разных бутстрап-выборках.\n",
    "2. Параметр variance падает соответственно количеству estimator'ов (чем больше n_estimators, тем ниже становится variance, но в какой-то момент, естественно, улучшение заканчивается, в данном случае variance остановился на значении около трех), bias остается практически таким же.\n",
    "3. Да, результат эксперимента соотносится с теорией. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. More Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we will be working with [Billionaires Statistics Dataset](https://www.kaggle.com/datasets/nelgiriyewithana/billionaires-statistics-dataset) to solve a classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T21:46:27.145107Z",
     "start_time": "2024-11-13T21:46:27.101156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>finalWorth</th>\n",
       "      <th>category</th>\n",
       "      <th>personName</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>source</th>\n",
       "      <th>industries</th>\n",
       "      <th>countryOfCitizenship</th>\n",
       "      <th>...</th>\n",
       "      <th>cpi_change_country</th>\n",
       "      <th>gdp_country</th>\n",
       "      <th>gross_tertiary_education_enrollment</th>\n",
       "      <th>gross_primary_education_enrollment_country</th>\n",
       "      <th>life_expectancy_country</th>\n",
       "      <th>tax_revenue_country_country</th>\n",
       "      <th>total_tax_rate_country</th>\n",
       "      <th>population_country</th>\n",
       "      <th>latitude_country</th>\n",
       "      <th>longitude_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>211000</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>74.0</td>\n",
       "      <td>France</td>\n",
       "      <td>Paris</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "      <td>France</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>$2,715,518,274,227</td>\n",
       "      <td>65.6</td>\n",
       "      <td>102.5</td>\n",
       "      <td>82.5</td>\n",
       "      <td>24.2</td>\n",
       "      <td>60.7</td>\n",
       "      <td>67059887.0</td>\n",
       "      <td>46.227638</td>\n",
       "      <td>2.213749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>180000</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>51.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>$21,427,700,000,000</td>\n",
       "      <td>88.2</td>\n",
       "      <td>101.8</td>\n",
       "      <td>78.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>36.6</td>\n",
       "      <td>328239523.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>114000</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>59.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Medina</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Technology</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>$21,427,700,000,000</td>\n",
       "      <td>88.2</td>\n",
       "      <td>101.8</td>\n",
       "      <td>78.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>36.6</td>\n",
       "      <td>328239523.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>107000</td>\n",
       "      <td>Technology</td>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>78.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Lanai</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>Technology</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>$21,427,700,000,000</td>\n",
       "      <td>88.2</td>\n",
       "      <td>101.8</td>\n",
       "      <td>78.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>36.6</td>\n",
       "      <td>328239523.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>106000</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "      <td>Warren Buffett</td>\n",
       "      <td>92.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>Berkshire Hathaway</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "      <td>United States</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>$21,427,700,000,000</td>\n",
       "      <td>88.2</td>\n",
       "      <td>101.8</td>\n",
       "      <td>78.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>36.6</td>\n",
       "      <td>328239523.0</td>\n",
       "      <td>37.090240</td>\n",
       "      <td>-95.712891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank  finalWorth               category                personName   age  \\\n",
       "0     1      211000       Fashion & Retail  Bernard Arnault & family  74.0   \n",
       "1     2      180000             Automotive                 Elon Musk  51.0   \n",
       "2     3      114000             Technology                Jeff Bezos  59.0   \n",
       "3     4      107000             Technology             Larry Ellison  78.0   \n",
       "4     5      106000  Finance & Investments            Warren Buffett  92.0   \n",
       "\n",
       "         country    city              source             industries  \\\n",
       "0         France   Paris                LVMH       Fashion & Retail   \n",
       "1  United States  Austin       Tesla, SpaceX             Automotive   \n",
       "2  United States  Medina              Amazon             Technology   \n",
       "3  United States   Lanai              Oracle             Technology   \n",
       "4  United States   Omaha  Berkshire Hathaway  Finance & Investments   \n",
       "\n",
       "  countryOfCitizenship  ... cpi_change_country           gdp_country  \\\n",
       "0               France  ...                1.1   $2,715,518,274,227    \n",
       "1        United States  ...                7.5  $21,427,700,000,000    \n",
       "2        United States  ...                7.5  $21,427,700,000,000    \n",
       "3        United States  ...                7.5  $21,427,700,000,000    \n",
       "4        United States  ...                7.5  $21,427,700,000,000    \n",
       "\n",
       "  gross_tertiary_education_enrollment  \\\n",
       "0                                65.6   \n",
       "1                                88.2   \n",
       "2                                88.2   \n",
       "3                                88.2   \n",
       "4                                88.2   \n",
       "\n",
       "  gross_primary_education_enrollment_country life_expectancy_country  \\\n",
       "0                                      102.5                    82.5   \n",
       "1                                      101.8                    78.5   \n",
       "2                                      101.8                    78.5   \n",
       "3                                      101.8                    78.5   \n",
       "4                                      101.8                    78.5   \n",
       "\n",
       "  tax_revenue_country_country total_tax_rate_country population_country  \\\n",
       "0                        24.2                   60.7         67059887.0   \n",
       "1                         9.6                   36.6        328239523.0   \n",
       "2                         9.6                   36.6        328239523.0   \n",
       "3                         9.6                   36.6        328239523.0   \n",
       "4                         9.6                   36.6        328239523.0   \n",
       "\n",
       "  latitude_country longitude_country  \n",
       "0        46.227638          2.213749  \n",
       "1        37.090240        -95.712891  \n",
       "2        37.090240        -95.712891  \n",
       "3        37.090240        -95.712891  \n",
       "4        37.090240        -95.712891  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('Billionaires Statistics Dataset.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['selfMade'])\n",
    "X = df.drop('selfMade', axis=1)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 <a id=\"task2_1\"></a> (1 point)\n",
    "\n",
    "Let's start with data preprocessing. \n",
    "\n",
    "0. Drop columns, which are not usefull (e.g. a lot of missing values). Motivate your choice. \n",
    "1. Split dataset into train and test\n",
    "2. You've probably noticed that we have both categorical and numerical columns. Here is what you need to do with them:\n",
    "    - Categorical: Fill missing values and apply one-hot-encoding (if there are more than 10 unique values in a column, use `min_frequency` and/or `max_categories` parameter)\n",
    "    - Numeric: Fill missing values\n",
    "    \n",
    "Use `ColumnTranformer` to define a single transformer for all the columns in the dataset. It takes as input a list of tuples\n",
    "\n",
    "```\n",
    "ColumnTransformer([\n",
    "    ('name1', transform1, column_names1),\n",
    "    ('name2', transform2, column_names2)\n",
    "])\n",
    "```\n",
    "\n",
    "Pay attention to an argument `remainder='passthrough'`. [Here](https://scikit-learn.org/stable/modules/compose.html#column-transformer) you can find some examples of how to use column transformer. \n",
    "    \n",
    "Since we want to apply 2 transformations to categorical feature, it is very convenient to combine them into a `Pipeline`:\n",
    "\n",
    "```\n",
    "double_tranform = make_pipeline(\n",
    "                        transform_1,\n",
    "                        transform_2\n",
    "                        )\n",
    "```\n",
    "\n",
    "P.S. Choose your favourite way to fill missing values. \n",
    "\n",
    "*Hint* Categorical column usually have `dtype = 'object'`. This may help to obtain list of categorical and numerical columns on the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Droped columns (если больше 0.4 части всех значений пустые): `'organization', 'title', 'state', 'residenceStateRegion'`\n",
    "Посмотрел numeric столбцы на корреляцию, максимальная была 0.78, но в целом почти все значения были до 0.5, так что решил не дропать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "\n",
    "missing = X.isnull().mean()\n",
    "to_drop = missing[missing > 0.4].index.tolist()\n",
    "X = X.drop(columns=to_drop)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13)\n",
    "\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_features = X.select_dtypes(include=['number']).columns\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy='most_frequent'),\n",
    "    OneHotEncoder(handle_unknown='ignore', min_frequency=0.01)\n",
    ")\n",
    "\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('categorical', categorical_transformer, categorical_features),\n",
    "    ('numerical', numerical_transformer, numerical_features)\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "X_train = column_transformer.fit_transform(X_train)\n",
    "X_test = column_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 <a id=\"task2_2\"></a> (0.7 points)\n",
    "\n",
    "Fit and compare 5 different models (use sklearn): Gradient Boosting, Random Forest, Decision Tree, SVM, Logitics Regression\n",
    "    \n",
    "* Choose one classification metric and justify your choice .\n",
    "* Compare the models using score on cross validation. Mind the class balance when choosing the cross validation. (You can read more about different CV strategies [here](https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold))\n",
    "* Which model has the best performance? Which models overfit or underfit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting\n",
      "Train: 0.852\n",
      "Test: 0.745\n",
      "\n",
      "\n",
      "Random Forest\n",
      "Train: 0.851\n",
      "Test: 0.764\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Train: 0.804\n",
      "Test: 0.710\n",
      "\n",
      "\n",
      "SVM\n",
      "Train: 0.808\n",
      "Test: 0.414\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Train: 0.806\n",
      "Test: 0.414\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "models = {\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=5000)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n",
    "    test_scores = []\n",
    "    \n",
    "    \n",
    "    for _, val in cv.split(X_test, y_test):   \n",
    "        y_pred = model.predict(X_test[val])\n",
    "        \n",
    "        score = f1_score(y_test[val], y_pred, average='macro')\n",
    "        test_scores.append(score)\n",
    "    \n",
    "    print(model_name)\n",
    "    print(f'Train: {np.mean(train_scores):.3f}')\n",
    "    print(f'Test: {np.mean(test_scores):.3f}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше себя показали модели градиентного бустинга и рандомного леса. SVM и LogReg на тренировочной выборке показывают себя чуть лучше чем решающее дерево, но из значений f1 на тестовой выборке сразу становится понятно, что SVM и LogReg переобучились, f1 score в два раза меньше на тесте, чем на треине. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 <a id=\"task2_3\"></a> (0.5 points)\n",
    "\n",
    "More Gradient Boosting. You will have to take one of the three popular boosting implementations (xgboost, lightgbm, catboost). Select hyperparameters (number of trees, learning rate, depth) on cross-validation and compare with the methods from the previous task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n",
      "Best F1: 0.8596874259419186\n",
      "Train: 0.857\n",
      "Test: 0.725\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'max_depth': [2, 3, 7, 10]\n",
    "}\n",
    "\n",
    "\n",
    "lgb_params = {\"verbose\": -1}\n",
    "gbm_model = LGBMClassifier(**lgb_params, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gbm_model, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='f1'\n",
    "                          )\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1:\", grid_search.best_score_)\n",
    "\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "train_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n",
    "test_scores = []\n",
    "\n",
    "for _, val in cv.split(X_test, y_test):   \n",
    "    y_pred = model.predict(X_test[val])\n",
    "    \n",
    "    score = f1_score(y_test[val], y_pred, average='macro')\n",
    "    test_scores.append(score)\n",
    "\n",
    "print(f'Train: {np.mean(train_scores):.3f}')\n",
    "print(f'Test: {np.mean(test_scores):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем небольшое улучшение на тренировочной выборке, но на тестовой LightGBM показывает себя немного хуже, чем градиентный бустинг и рандомный лес."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 <a id=\"task2_4\"></a> (0.7 points)\n",
    "\n",
    "Now let's train more fancy ensembles:\n",
    "\n",
    "* Bagging with decision trees as base estimators\n",
    "* Bagging with gradient boosting (with large amount of trees, >100) as base estimators\n",
    "* [Voting classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier) \n",
    "* [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) with Logistic Regression as a final model\n",
    "* [Stacking Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingClassifier.html#sklearn.ensemble.StackingClassifier) with Gradeint Boosting as a final model\n",
    "\n",
    "\n",
    "If not stated in the task, feel free to tune / choose hyperparameters and base models.\n",
    "\n",
    "Answer the questions:\n",
    "* Which model has the best performance?\n",
    "* Does bagging reduce overfiting of the gradient boosting with large amount of trees? \n",
    "* What is the difference between voting and staking? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, model_name):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='f1')\n",
    "    test_scores = []\n",
    "    \n",
    "    for _, val in cv.split(X_test, y_test):   \n",
    "        y_pred = model.predict(X_test[val])\n",
    "        \n",
    "        score = f1_score(y_test[val], y_pred, average='macro')\n",
    "        test_scores.append(score)\n",
    "    \n",
    "    print(f'Train: {np.mean(train_scores):.3f}')\n",
    "    print(f'Test: {np.mean(test_scores):.3f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.843\n",
      "Test: 0.750\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bagging_tree = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)\n",
    "fit_model(bagging_tree, \"Bagging with decision trees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.854\n",
      "Test: 0.749\n"
     ]
    }
   ],
   "source": [
    "bagging_gradient_boosting = BaggingClassifier(estimator=GradientBoostingClassifier(), n_estimators=200, random_state=42)\n",
    "fit_model(bagging_gradient_boosting, \"Bagging with gradient boosting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остальные модели не получилось выполнить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 <a id=\"task2_5\"></a> (0.1 points)\n",
    "\n",
    "Report the test score for the best model, that you were able to train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1-Score, Random Forest\n",
    "\n",
    "Test: 0.753 \n",
    "Train: 0.855"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
